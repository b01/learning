# Scheduler

Every Pod has a field `nodeName` that by default is not set.
1. The scheduler goes though all the Pods and looks for those that do not have
   this property set, and selects them as candidates for scheduling.
2. It then selects a Pod and runs an algorithm to identify the right node for
   the Pod.
3. It then schedules the Pod to be placed on the node by setting the `nodeName`
   to the name of the node, for the Pod, by creating a binding object.

Ensures that the sum of the resource requests of the scheduled containers is
less than the capacity of the node.

## Manual Scheduling

To manually assign a node you have 2 ways:
1. You can assign a nodeName at the time of making the new Pod.
2. Make a binding object, as the scheduler does, for the Pod, but this must be sent as a JSON object over to the Pods biding API with the data:
   ```yaml
   apiVersion: v1
   kind: Binding
   metadata:
     name: nginx
   target:
     apiVersion: v1
     kind: Node
     name: node02
   ```
   ```sh
   SERVER='control-plane:6443'
   POD_NAME="nginx"
   cat <<HDOC > pod-binding-data.json
   {
     "apiVersion": "v1",
     "kind": "Binding",
     "metadata": {
        "name": "nginx",
     }
     "target": {
       "apiVersion": "v1",
       "kind": "Node",
       "name": "worker-01"
     }
   }
   HDOC

   curl -k --header "Content-Type: application/json" \
       --header "Authorization: Bearer ${K8_TOKEN}" \
       --request POST --data @./pod-binding-data.json \
       https://${SERVER}/api/v1/namespaces/default/pods/${POD_NAME}/binding
   ```

## Configure Kubernetes Scheduler

```yaml
apiVersion: v1
kind: Pod
metadata:
   name: multi-pod
   labels:
      name: multi-pod
spec:
   containers:
      - name: alpha
        image: nginx
        env:
           - name: "name"
             value: "alpha"
      - name: beta
        image: busybox
        command: [ sleep, "4800" ]
        env:
           - name: "name"
             value: "beta"
---
apiVersion: v1
kind: Pod
metadata:
   name: non-root-pod
   labels:
      name: non-root-pod
spec:
   securityContext:
      runAsUser: 1000
      fsGroup: 2000
   containers:
      - name: non-root-pod
        image: redis:alpine
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
   name: ingress-to-nptest
spec:
   podSelector:
      matchLabels:
         run: np-test-1
   policyTypes:
      - Ingress
   ingress:
      - ports:
           - protocol: TCP
             port: 80
---
apiVersion: v1
kind: Pod
metadata:
   name: prod-redis
   labels:
      name: prod-redis
spec:
   containers:
      - name: prod-redis
        image: redis:alpine
   tolerations:
      - key: "env_type"
        operator: "Equal"
        value: "production"
        effect: "NoSchedule"
---
apiVersion: v1
kind: Pod
metadata:
   name: hr-pod
   namespace: hr
   labels:
      name: hr-pod
      environment: production
      tier: frontend
spec:
   containers:
      - name: hr-pod
        image: redis:alpine
```

## Taints

Allow a node to repel a set of Pods.

You add a taint to a node using kubectl taint. For example,
`kubectl taint nodes node1 key1=value1:NoSchedule`

To remove the taint added by the command above, you can run:
`kubectl taint nodes node1 key1=value1:NoSchedule-`

The node controller automatically taints a Node when certain conditions are
true. The following taints are built in:
* node.kubernetes.io/not-ready: Node is not ready. This corresponds to the
  NodeCondition Ready being "False".
* node.kubernetes.io/unreachable: Node is unreachable from the node controller.
  This corresponds to the NodeCondition Ready being "Unknown".
* node.kubernetes.io/memory-pressure: Node has memory pressure.
* node.kubernetes.io/disk-pressure: Node has disk pressure.
* node.kubernetes.io/pid-pressure: Node has PID pressure.
* node.kubernetes.io/network-unavailable: Node's network is unavailable.
* node.kubernetes.io/unschedulable: Node is unschedulable.
* node.cloudprovider.kubernetes.io/uninitialized  set when the `kubelet` is
  started with an "external" cloud provider. Removed after the
  `cloud-controller-manager` initializes the node.

In case a node is to be drained, the node controller or the kubelet adds
relevant taints with NoExecute effect.

In cases where the node is unreachable, and the API server is unable to delete
the Pods running on that node; the pods that are scheduled for deletion may
continue to run.

Note: The control plane limits the rate of adding new taints to nodes.

You can specify `tolerationSeconds` for a Pod to define how long that Pod stays
bound to a failing or unresponsive Node.
```yaml
tolerations:
- key: "node.kubernetes.io/unreachable"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 6000
```

NOTE: The default is `tolerationSeconds=300`.

DaemonSet Pods are created with `NoExecute` tolerations for taints (and with no
tolerationSeconds):
* `node.kubernetes.io/unreachable`
* `node.kubernetes.io/not-ready`

### Taint Nodes by Condition

The controller adds taints to nodes based on conditions such as disk-pressure,
and the scheduler can then take those taints into consideration. This allows
separation of concerns. The controller handles conditions, while the schedule
makes use of the taints it provides.

If a Pod ends up on any nodes with these conditions it could mean they are
bypassing the scheduler by setting the `.spec.nodeName` or adding tolerations.

DemonSets adds tolerations for these `NoSchedule` taints.
* node.kubernetes.io/memory-pressure
* node.kubernetes.io/disk-pressure
* node.kubernetes.io/pid-pressure (1.14 or later)
* node.kubernetes.io/unschedulable (1.10 or later)
* node.kubernetes.io/network-unavailable

Administrators can also [taint individual devices] when the cluster uses dynamic
resource allocation to manage special hardware.

## Tolerations

Tolerations are applied to Pods. Tolerations allow the scheduler to schedule
Pods with matching taints. While they allow scheduling, they don't guarantee it,
since scheduling has to make other considerations such as CPU resources.

A `toleration` "matches" a `taint` if the keys are the same and the effects are
the same, and:
* the operator is `Exists` (in which case no value should be specified), or
* the operator is Equal and the values should be equal.

You specify a toleration for a pod in the PodSpec.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  tolerations:
  - key: "example-key"
    operator: "Exists"
    effect: "NoSchedule"
```

The default Kubernetes scheduler takes taints and tolerations into account
when selecting a node to run a particular Pod. However, if you manually
specify the `.spec.nodeName` for a Pod, that action bypasses the scheduler;
the Pod is then bound onto the node where you assigned it, even if there are
NoSchedule taints on that node that you selected. If this happens and the node
also has a NoExecute taint set, the kubelet will eject the Pod unless there is
an appropriate tolerance set.

There are two special cases:
* If the `key` is empty, then the operator must be `Exists`, which matches all
  keys and values. Note that the effect still needs to be matched at the same
  time.
* An empty effect matches all effects with key `key1`.

The allowed values for the effect field are:
* NoExecute
* NoSchedule
* PreferNoSchedule


## Requests and limits

You can optionally specify how much of each resource a container needs.

It's allowed for a container to use more resource than its request.

Both `cpu` and `memory` limits are applied by the `kubelet` and are ultimately
enforced by the kernel with cgroups.

`cpu` limits are enforced by CPU throttling, is a hard limit the kernel
enforces.

`memory` limits are enforced by the kernel with out-of-memory (OOM) kills,
meaning the kernel may terminate it.

If you specify a limit but no request, and no admission-time mechanism has
applied a default request; then the limit is used as the request.

**Resource types**

`cpu` is specified in units of [Kubernetes CPUs]. 1 CPU unit is equivalent to
1 physical CPU core, or 1 virtual core. Decimal `0.5` or
milliCPU `500m` forms are allowed, with milliCPU preferred.

`memory` is specified in units of bytes. Express memory as a plain integer or
fixed-point number and a quantity suffix (E, P, T, G, M, k, Ei, Pi, Ti, Gi, Mi,
Ki). Pay attention to upper/lower case.

Linux workloads, you can specify huge page resources, or blocks of memory that
are much larger than the default page size.

```yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
    - name: app
      image: nginx
      resources:
        limits:
          cpu: "0.5"
          memory: "100Mi"
        requests:
          cpu: "0.5"
          memory: "50Mi"
---
apiVersion: v1
kind: Pod
metadata:
  name: pod-resources-example
  namespace: demo
spec:
  resources:
    limits:
      cpu: "1"
      memory: "200Mi"
    requests:
      cpu: "500m"
      memory: "100Mi"
  containers:
    - name: app
      image: images.my-company.example/app:v4
      resources:
        requests:
          memory: "64Mi"
          cpu: "250m"
        limits:
          memory: "128Mi"
          cpu: "500m"
    - name: log-aggregator
      image: images.my-company.example/log-aggregator:v6
      resources:
        requests:
          memory: "64Mi"
          cpu: "250m"
        limits:
          memory: "128Mi"
          cpu: "500m"

```

## Resource requests and limits of Pod and container

CPU and memory are collectively referred to as compute resources.

For a container you can specify the following:
* spec.containers[].resources.limits.cpu
* spec.containers[].resources.limits.memory
* spec.containers[].resources.limits.hugepages-<size>
* spec.containers[].resources.requests.cpu
* spec.containers[].resources.requests.memory
* spec.containers[].resources.requests.hugepages-<size>

A Pod's resource request/limit is the sum of the resource requests/limits of
that type for each container. Or replicas times the sum.

Starting in Kubernetes 1.32, you can also specify resource requests and limits
at the Pod level. At the Pod level, Kubernetes 1.33 only supports resource
requests or limits for specific resource types: cpu and / or memory.

For a Pod you specify the following:
* spec.resources.limits.cpu
* spec.resources.limits.memory
* spec.resources.requests.cpu
* spec.resources.requests.memory

The scheduler ensures that, for each resource type, the sum of the resource
requests of the scheduled containers is less than the capacity of the node.

You can find more details on this subject at
[How Kubernetes applies resource requests and limits].


Monitoring compute and memory resource usage is possible as the `kubelet`
reports the resource usage of a Pod as part of is `status`, or its usage can be
retrieved from the Metrics API directly.

## Considerations for memory backed emptyDir volumes

When `emptyDir.medium` field is set to "Memory", Kubernetes mounts a **tmpfs**
(RAM-backed filesystem) for you.

If you do not specify a sizeLimit for an `emptyDir` volume, that volume may
consume up to that Pod's memory limit, or all available memory on the node.

Files stored on a memory-backed volume are almost entirely managed by the user
application.

Administrators can also set ResourceQuota that limits memory use.

As an alternative, administrator can enforce size limits for `emptyDir` volumes
in new Pods using a policy mechanism such as [ValidationAdmissionPolicy]

## Local ephemeral storage

Nodes have local ephemeral storage, backed by locally-attached writeable
devices or, sometimes, by RAM.

To make the resource quota work on ephemeral-storage, two things need to be
done:
* Set the resource quota for ephemeral-storage in a namespace.
* Specify limits for the ephemeral-storage resource in the Pod spec.

If a node fails, the data in its ephemeral storage can be lost

Managing local ephemeral storage as a resource, then the `kubelet` measures
storage use in:
* emptyDir volumes
* directories holding node-level logs
* writeable container layers

The kubelet supports different ways to measure Pod storage use:
* Periodic scanning
* File system project quota

Process ID (PID) limits allow for the configuration of a kubelet to limit the
number of PIDs that a given Pod can consume.

## Troubleshooting

If the scheduler cannot find any node where a Pod can fit, the Pod remains
unscheduled until a place can be found.

use kubectl to view the events for a Pod:
`kubectl describe pod frontend | grep -A 9999999999 Events`

options:
* Add more nodes to the cluster.
* Terminate unneeded Pods to make room for pending Pods.
* Check that the Pod is not larger than all the nodes. For example,
* Check for node taints.

check node capacities and amounts allocated:
`kubectl describe nodes <node-name`

---

[taint individual devices]: https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/#device-taints-and-tolerations
[Kubernetes CPUs]: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu
[How Kubernetes applies resource requests and limits]: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-limits-are-run
[ValidationAdmissionPolicy]: https://kubernetes.io/docs/reference/access-authn-authz/validating-admission-policy/