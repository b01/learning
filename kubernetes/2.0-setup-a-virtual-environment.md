# `Setup A Virtual Environment`


Time to spin-up a local virtual environment. Then initialize each machine
by making sure all the initial software and network configurations are in
place. This prepares the machines to either serve as a control plane or worker
node.

## Spin Up the Environment

1. Install [Vagrant] and [VirtualBox] if you have not already. You may be able to
   substitute VirtualBox with Hyper-V if your OS is Windows.
2. Download this [Vagrantfile] to a directory and open a terminal and run
   `vagrant up`.
   NOTE: Each machines private IP is hard-coded in the Vagrantfile so that they
   are predictable for the sake of these instructions. The
   `control-plane-01=192.168.56.11`, `worker-01=192.168.0.21`, and
   `worker-01=192.168.0.22`. If you increase the number of nodes, there IPs are
   sequential.
3. As each machine completes the boot process, you can test that you can SSH
   into the machine with `vagrant ssh <machine-hostname>`. If you need to see
   the hostname of the VMs, run `vagrant status`.
4. Optionally [Configure SSH From A JumpBox].
TIP: Open a new terminal for each machine you want to SSH into. The session
should last as long as you have the terminal open. Keep them open as long as
you may need them to save time.

## Machine Initialization

However you choose, you'll need to execute the following steps on each VM. You
can SSH into each machine using the command `vagrant ssh <machine-hostname>`.

NOTE: You MUST be in the same directory where you ran `vagrant up` to SSH into
that machine using the `vagrant ssh`; this is specific to the Vagrant `ssh`
subcommand. The _actual_ ssh command does not have this quirk.

Determine the init system your VM uses by running `ps -p 1 -o comm=`. You need
to know this when configuring the `kubelet` on each machine.

NOTE: Currently, Kubernetes v1.33 defaults to `systemd`. In the future it should
autodetect it.

Also [Identify the cgroup version on Linux Nodes] of a machine by running
`stat -fc %T /sys/fs/cgroup/`; for cgroup v2, the output is `cgroup2fs` or
for cgroup v1, the output is `tmpfs`.

Now lets get each machine ready:

1. Make sure the OS is up-to-date and install some tools:
   ```shell
   sudo apt update && sudo apt upgrade
   # apt-transport-https may be a dummy package; if so, you can skip that package
   sudo apt install -y \
      apt-transport-https ca-certificates curl gpg jq openssl wget vim
   ```
2. Swap configuration
   1. Check if swap is on `sudo swapon --show`
   2. If it is, disable it temporarily with `sudo swapoff -a`. Check
      your system docs to see how to disable it permanently.
   3. To persist this change on reboots on Ubuntu edit `sudo vi /etc/fstab` and
      add the comment marker `#` symbol at the beginning of the line containing
      the swap partition, for example:
      ```text
      #/swap.img       none    swap    sw      0       0
      ```
   4. Then save the file, with vim, you type `:`, then `x`, then hit enter.
3. Configure IP forwarding:
   1. Run `sysctl net.ipv4.ip_forward` to verify "IPv4 packet forwarding" is
      set to "1".
   2. If not, then run:
      ```shell
      echo  "net.ipv4.ip_forward = 1" | sudo tee /etc/sysctl.d/k8s.conf
      ```
   3. Optionally [Enable IPv6 packet forwarding]:
      1. check if it is turned on with `sysctl net.ipv6.conf.all.forwarding`
      2. If not, then run:
        ```shell
        echo "net.ipv6.conf.all.forwarding = 1" | sudo tee -a /etc/sysctl.d/k8s.conf
        ```
   4. Apply sysctl params without reboot:
      ```shell
      sudo sysctl --system
      ```

   NOTE: Kubernetes requires that the kernel allows IP packet forwarding. This
   may be disabled by default.
4. This guide uses a CNI network plugin that uses `iptables` and the
   `bridge-netfilter` architecture of the Linux kernel. So we need to load the
   [br_netfilter] kernel module and enable IP packet filter for Linux based
   bridge networks.
   ```bash
   cat <<TXT | sudo tee -a /etc/modules-load.d/modules.conf
   br_netfilter
   TXT
   sudo modprobe br_netfilter
   # Enable for IPv4 and IPv6 (a.k.a dual-stack), then load (with `sysctl -p`) in sysctl settings from the file specified.
   cat <<TXT | sudo tee -a /etc/sysctl.d/k8s.conf
   net.bridge.bridge-nf-call-iptables = 1
   net.bridge.bridge-nf-call-ip6tables = 1
   TXT
   # Load in sysctl settings from the file specified
   sudo sysctl -p /etc/sysctl.d/k8s.conf
   ```

   NOTE: The [ebtables] program is a filtering tool for Linux-based bridge
   firewalls. It can be combined with the `bridge-netfilter` architecture,
   which is a part of the standard Linux kernel, to allow `iptables` to also
   filter bridged IP packets. This enables the functionality of a stateful
   transparent firewall.
5. Gather each machines private IP. You'll want to run `ip address` on each
   machine to find their private IP by observing the second network interface.
   These IPs are actually hard-coded in the [Vagrantfile] to be:
   ```text
   192.168.56.11 = control-plane-01
   192.168.56.21 = worker-01
   192.168.56.22 = worker-02
   ```
   On each VM append the IP of each machine to the `/etc/hosts` file, which
   will allow communicating by hostname instead of IP address, which should
   reduce errors when copying files around.
   ```shell
   cat <<TXT | sudo tee -a /etc/hosts
   192.168.56.11 control-plane control-plane-01
   192.168.56.21 worker-01
   192.168.56.22 worker-02
   ```
6. Update the SSH daemon on each node to allow keyboard-interactive
   authentication:
   ```shell
   sudo sed -i 's/KbdInteractiveAuthentication no/KbdInteractiveAuthentication yes/' /etc/ssh/sshd_config
   sudo systemctl restart ssh
   ```
   NOTE: Some VMs may have this turned this off. Without it, we will not be able
   to run `ssh-copy-id` successfully.
7. Back on the `control-plane-01` node make an SSH key, then use `ssh-copy-id`
   to allow SSH key based authentication from `control-plane-01`. This will
   allow running commands on each node remotely.
   ```shell
   # you can just hit enter and leave the password blank if your just practicing.
   ssh-keygen
   ssh-copy-id vagrant@$worker-01
   ssh-copy-id vagrant@$worker-02
   ```

Next: [Install containerd]

---

[Enable IPv6 packet forwarding]: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/dual-stack-support/#prerequisite-ipv6-forwarding
[Vagrantfile]: /kubernetes/samples/Vagrantfile
[Vagrant]: https://developer.hashicorp.com/vagrant
[VirtualBox]: https://www.virtualbox.org/
[br-netfilter]: https://ebtables.netfilter.org/documentation/bridge-nf.html
[Install containerd]: /kubernetes/3.0-install-containerd.md#install-containerd
[Identify the cgroup version on Linux Nodes]: https://kubernetes.io/docs/concepts/architecture/cgroups/#check-cgroup-version
[ebtables]: https://ebtables.netfilter.org/
[br_netfilter]: https://ebtables.netfilter.org/documentation/bridge-nf.html
