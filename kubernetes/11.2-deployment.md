# Deployment

Manages a set of Pods to run an application workload.

It provides declarative updates for Pods and ReplicaSets.

It describes a desired state, and the Deployment Controller changes the
actual state to the desired state at a controlled rate.

Deployment ensures that only a certain number of Pods are down while they are
being updated. By default, it ensures that at least 75% of the desired number
of Pods are up (25% max unavailable). It also ensures that only a certain
number of Pods are created above the desired number of Pods. By default, it
ensures that at most 125%

A Deployment spec should have at least these top-level fields:
* `apiVersion` - can be `v1` or `apps\v1`.
* `kind` - set to `Deployment` to specify its resource type.
* `metadata` - a map which should contain "name", and "labels" fields,
  "labels" can be a map with any keys you desire/need.
* `spec` - additional information pertaining to the object you indicated in
  the `kind` property, refer to documentation for what attributes to use per
  object. When kind is set to a `Pod` we can use the property `containers`
  which is a list; `.spec.replicas` makes a ReplicaSet with the number
  indicated. `.spec.selector` field defines how the ReplicaSet finds which Pods
  to manage, more sophisticated selection rules are possible. The
  `.spec.template` field is that same as a [PodSpec]. `.spec.strategy`
  specifies the strategy used to replace old Pods by new ones.
  `.spec.strategy.type` can be "Recreate" or "RollingUpdate". "RollingUpdate"
  is the default value.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: http-server-dp
spec:
  replicas: 1
  selector:
    matchLabels:
      uid: abc123
  template:
    metadata:
      labels:
        uid: abc123
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
```

NOTE: The `pod-template-hash` label is added by the Deployment controller and
should be treated as read-only, so do NOT set it. This ensures that ReplicaSets
do not overlap.

## Rolling Update

A rolling update allows a Deployment update to take place with zero downtime.

By default, the maximum number of Pods that can be unavailable during an
update and the maximum number of new Pods that can be created, is one, but
this is configurable.

If a Deployment is exposed publicly with a Service, it will load-balance the
traffic only to available Pods during the update.

A Rollout is triggered and makes a new revision when:
1. you first make a deployment, which makes a new rollout revision.
2. `.spec.template` is changed, for example if the labels or container images.

NOTE: Other updates, such as scaling the Deployment, do not trigger a rollout.

Kubernetes doesn't count terminating Pods when calculating the number of
availableReplicas. As a result, you may notice more Pods than expected during a
rollout, and resources consumed may be more than replicas + maxSurge. This
is to be expected until the terminationGracePeriodSeconds of the terminating
Pods expires.

You can update a Deployment while an existing rollout is in progress. For every
new Deployment a new ReplicaSet is made. The ReplicaSet that it was scaling up
previously will be added to a list of old ReplicaSets and start scaling it down
immediately.

Label selector updates can cause ReplicaSets to become orphans (no Deployment to
manage them). In API version `apps/v1`, a Deployment's label selector is
read-only after it gets created. If you MUST change a label, it's best to delete
the deployment first.

## Rolling Back a Deployment

By default, all rollout history is kept in the system, making them available
for rollback.

See a deployments revision history with `kubectl rollout history deploy/<name>`.

To see the details of each revision, run:
```shell
kubectl rollout history deploy/<name> --revision=2
```

NOTE:  You can configure the revision history limit.

The Deployment controller stops bad rollouts automatically, and stops
scaling up the new ReplicaSet.

Should a rollout get stuck, then rollback to a previous revision with
`kubectl rollout undo deploy/<name>`.

Rollback to a specific revision with:
```shell
kubectl rollout undo deploy/<name> --to-revision=2
```

## Deployment Strategies

**Recreate**

1. destroy all pods
2. rollout new pods.

**Rolling Update** is the default

1. delete 1 rollout 1 new one
2. Repeat step 1 until all pods are replaced.

You can see a difference in the update strategy when you `describe` the
deployment and view the StrategyType field and the Events.

You can specify the **CHANGE-CAUSE** message by annotating the Deployment or
manually editing the manifest of the resource. For example:
```shell
kubectl annotate deployment/nginx-deployment kubernetes.io/change-cause="image updated to 1.16.1"
```

## Scaling a Deployment

Set up an [HorizontalPodAutoscaler] (HPA) and choose the minimum and maximum
number of Pods you want to run based on the CPU utilization.

Your Kubernetes cluster must:
* be at or later than version 1.23
* have a Metrics Server deployed and configured.
* [Horizontal Pod Autoscaling] MUST be enabled in your cluster.

NOTE: The "horizontal-pod-autoscaler-controller" should be enabled by default.
This is because for the `kube-controller-manager` configuration the option
`--controllers` defaults to "*" which includes all default controllers. You
can review the logs to see if it was started with
`kubectl logs -n kube-system kube-controller-manager-<control-plane-hostname> | grep horizontal-pod-autoscaler`
Assuming the logs have not been truncated.

## You Should Know

These are important features of Deployment to be aware of.

**Proportional scaling**
When you or an HPA scales a RollingUpdate Deployment that is in the
middle of a rollout (either in progress or paused), the Deployment controller
balances the additional replicas in the existing active ReplicaSets
(ReplicaSets with Pods) in order to mitigate risk.

For example, you are running a Deployment with 10 replicas, maxSurge=3, and
maxUnavailable=2.
1. Start a new rolling update by setting a new image to nginx:1.28.0.
2. Before the update can finish, we perform another rolling update
   because we meant to nginx:1.29.0.
3. Now there are 2 rolling updates in progress.

The autoscaler increments the Deployment replicas to 15. The Deployment
controller needs to decide where to add these new 5 replicas.

If you weren't using proportional scaling, all 5 of them would be added in the
new ReplicaSet.

With proportional scaling, you spread the additional replicas across all
ReplicaSets.

Bigger proportions go to the ReplicaSets with the most replicas and lower
proportions go to ReplicaSets with less replicas.

**Pausing and Resuming a rollout**

You can pause rollouts.

This approach allows you to apply multiple fixes in between pausing and
resuming without triggering unnecessary rollouts.
1. Pause a rollout
2. Make as many updates as you wish.
3. Eventually resume the Deployment rollout.

Pause by running the following command:
`kubectl rollout pause deployment/nginx-deployment`

Resume rollouts
`kubectl rollout resume deployment/nginx-deployment`

Watch the status of the rollout until it's done.
`kubectl get rs --watch`

Get the status of the latest rollout:
`kubectl get rs`

**Deployment status**

A Deployment enters various states during its lifecycle. It can be progressing
while rolling out a new ReplicaSet, it can be complete, or it can fail to
progress.

## Useful Commands

Get help with using `kubectl` to make a Deployment
`kubectl create deploy --help`.

View all deployments by running `kubectl get deploy`.

Get details of your Deployment with `kubectl describe deploy <name>`.

Watch a deployment as it rolls out with `kubectl rollout status deploy/<name>`.

Update the deployment config YAML with `kubectl edit deploy/<name>`.

Set a single property with
`kubectl set image deploy/<name> <container-name>=<new-image>`

You can scale a Deployment by using the following command:
`kubectl scale deploy/nginx-deployment --replicas=10`

---

[PodSpec]: https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec
[HorizontalPodAutoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/
[Horizontal Pod Autoscaling]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
